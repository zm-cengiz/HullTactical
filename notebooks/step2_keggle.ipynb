{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4da5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make TF quiet and force python protobuf impl BEFORE importing TF (no internet install)\n",
    "import os, importlib, importlib.util\n",
    "from pathlib import Path\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "IN_KAGGLE = Path('/kaggle/input').exists()\n",
    "\n",
    "# Deterministic availability detection (no try/except)\n",
    "LGBM_AVAILABLE = importlib.util.find_spec(\"lightgbm\") is not None\n",
    "# To avoid protobuf/TF mismatches in Kaggle's offline runner, hard-disable TF on Kaggle\n",
    "LSTM_AVAILABLE = (not IN_KAGGLE) and (importlib.util.find_spec(\"tensorflow\") is not None)\n",
    "\n",
    "# Import only when available per above policy\n",
    "if LGBM_AVAILABLE:\n",
    "    import lightgbm as lgb\n",
    "\n",
    "if LSTM_AVAILABLE:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(f\"IN_KAGGLE={IN_KAGGLE}, LGBM_AVAILABLE={LGBM_AVAILABLE}, LSTM_AVAILABLE={LSTM_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56708c",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project directory\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_DIR = NOTEBOOK_DIR.parent\n",
    "\n",
    "# Detect Kaggle environment and set paths accordingly\n",
    "IN_KAGGLE = Path('/kaggle/input').exists()\n",
    "\n",
    "\n",
    "def resolve_kaggle_path(preferred: Path, default_filename: str) -> Path:\n",
    "    \"\"\"Resolve a data path when running on Kaggle.\n",
    "    Priority:\n",
    "    1) Environment variable override (e.g., TRAIN_PATH/TEST_PATH)\n",
    "    2) /kaggle/input/**/<default_filename>\n",
    "    3) First CSV found under /kaggle/input\n",
    "    4) Fallback to preferred path\n",
    "    \"\"\"\n",
    "    if not IN_KAGGLE:\n",
    "        return preferred\n",
    "\n",
    "    # Environment override, e.g., TRAIN_PATH or TEST_PATH\n",
    "    env_key = default_filename.upper().replace('.CSV', '') + '_PATH'\n",
    "    env_val = os.environ.get(env_key)\n",
    "    if env_val and Path(env_val).exists():\n",
    "        return Path(env_val)\n",
    "\n",
    "    # Try the standard filename within any dataset mounted in /kaggle/input\n",
    "    candidates = list(Path('/kaggle/input').glob(f'**/{default_filename}'))\n",
    "    if candidates:\n",
    "        return candidates[0]\n",
    "\n",
    "    # Fallback: any CSV under /kaggle/input\n",
    "    any_csv = list(Path('/kaggle/input').glob('**/*.csv'))\n",
    "    if any_csv:\n",
    "        print(f\"Warning: Could not find {default_filename}; using first CSV found: {any_csv[0]}\")\n",
    "        return any_csv[0]\n",
    "\n",
    "    # Last resort\n",
    "    print(f\"Warning: No CSV found under /kaggle/input; attempting preferred path: {preferred}\")\n",
    "    return preferred\n",
    "\n",
    "# Directories for artifacts/results (writeable on Kaggle: /kaggle/working)\n",
    "if IN_KAGGLE:\n",
    "    ARTIFACTS_DIR = Path('/kaggle/working/artifacts')\n",
    "    RESULTS_DIR = Path('/kaggle/working/results')\n",
    "else:\n",
    "    ARTIFACTS_DIR = PROJECT_DIR / 'artifacts'\n",
    "    RESULTS_DIR = PROJECT_DIR / 'results'\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'train_data_path': resolve_kaggle_path(PROJECT_DIR / 'data' / 'train.csv', 'train.csv'),\n",
    "    'test_data_path': resolve_kaggle_path(PROJECT_DIR / 'data' / 'test.csv', 'test.csv'),\n",
    "    'artifacts_dir': ARTIFACTS_DIR,\n",
    "    'results_dir': RESULTS_DIR,\n",
    "    'target_column': 'forward_returns',\n",
    "    'prediction_bounds': (0.0, 2.0),\n",
    "    'max_volatility_ratio': 1.2,  # 120% of benchmark\n",
    "    'n_splits': 5,  # For time-series cross-validation\n",
    "}\n",
    "\n",
    "# Ensure results/artifacts directories exist\n",
    "CONFIG['results_dir'].mkdir(parents=True, exist_ok=True)\n",
    "CONFIG['artifacts_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Feature list (same as Step 1)\n",
    "FEATURE_COLS = [\n",
    "    'V7', 'V13', 'E3', 'M4', 'P11', 'S2', 'I7', 'P2', 'P6', 'E17',\n",
    "    'M12', 'M11', 'E2', 'I2', 'E9', 'P8', 'P5', 'I5', 'I9', 'V12'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea871c13",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f138b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data: (9021, 98)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv(CONFIG['train_data_path'])\n",
    "print(f\"Loaded training data: {train_df.shape} from {CONFIG['train_data_path']}\")\n",
    "# Safely detect a date column before accessing it to avoid KeyError\n",
    "date_col = next((c for c in ['date','timestamp','datetime','time','Date','DATE'] if c in train_df.columns), None)\n",
    "if date_col:\n",
    "    date_min = pd.to_datetime(train_df[date_col], errors='coerce').min()\n",
    "    date_max = pd.to_datetime(train_df[date_col], errors='coerce').max()\n",
    "    if pd.notna(date_min) and pd.notna(date_max):\n",
    "        print(f\"Date range ({date_col}): {date_min} to {date_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned: 9,021 samples\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "X = train_df[FEATURE_COLS].copy()\n",
    "y = train_df[CONFIG['target_column']].copy()\n",
    "# Safely build a `dates` series from available date-like columns\n",
    "date_col = next((c for c in ['date','timestamp','datetime','time','Date','DATE'] if c in train_df.columns), None)\n",
    "if date_col:\n",
    "    dates = pd.to_datetime(train_df[date_col], errors='coerce')\n",
    "else:\n",
    "    dates = pd.Series(pd.NaT, index=train_df.index)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.ffill().bfill()\n",
    "\n",
    "# Remove rows with NaN\n",
    "valid_idx = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "X = X[valid_idx]\n",
    "y = y[valid_idx]\n",
    "dates = dates[valid_idx]\n",
    "\n",
    "print(f\"Data cleaned: {len(X):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54086327",
   "metadata": {},
   "source": [
    "## Time-Series Cross-Validation Setup\n",
    "\n",
    "Using **Walk-Forward** validation to respect temporal ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2cbab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=CONFIG['n_splits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9d3ca",
   "metadata": {},
   "source": [
    "## Model 1: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68fc02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 1: RANDOM FOREST\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5\n",
      "  MSE: 0.000148\n",
      "  MAE: 0.009316\n",
      "  R²: -0.014001\n",
      "\n",
      "Fold 2/5\n",
      "  MSE: 0.000105\n",
      "  MAE: 0.007374\n",
      "  R²: -0.080307\n",
      "\n",
      "Fold 3/5\n",
      "  MSE: 0.000105\n",
      "  MAE: 0.007374\n",
      "  R²: -0.080307\n",
      "\n",
      "Fold 3/5\n",
      "  MSE: 0.000177\n",
      "  MAE: 0.009373\n",
      "  R²: -0.018052\n",
      "\n",
      "Fold 4/5\n",
      "  MSE: 0.000177\n",
      "  MAE: 0.009373\n",
      "  R²: -0.018052\n",
      "\n",
      "Fold 4/5\n",
      "  MSE: 0.000069\n",
      "  MAE: 0.005733\n",
      "  R²: -0.016737\n",
      "\n",
      "Fold 5/5\n",
      "  MSE: 0.000069\n",
      "  MAE: 0.005733\n",
      "  R²: -0.016737\n",
      "\n",
      "Fold 5/5\n",
      "  MSE: 0.000131\n",
      "  MAE: 0.008184\n",
      "  R²: -0.020799\n",
      "\n",
      "==================================================\n",
      "RANDOM FOREST - AVERAGE RESULTS\n",
      "==================================================\n",
      "MSE: 0.000126 ± 0.000041\n",
      "MAE: 0.007996 ± 0.001515\n",
      "R²:  -0.029979 ± 0.028240\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 1: RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "    print(f\"\\nFold {fold}/{CONFIG['n_splits']}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_scaled = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train_scaled, y_train_fold)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = rf_model.predict(X_val_scaled)\n",
    "    \n",
    "    # Clip predictions to valid range\n",
    "    y_pred = np.clip(y_pred, CONFIG['prediction_bounds'][0], CONFIG['prediction_bounds'][1])\n",
    "    \n",
    "    # Evaluate\n",
    "    mse = mean_squared_error(y_val_fold, y_pred)\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred)\n",
    "    r2 = r2_score(y_val_fold, y_pred)\n",
    "    \n",
    "    rf_results.append({\n",
    "        'fold': fold,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"  MSE: {mse:.6f}\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    print(f\"  R²: {r2:.6f}\")\n",
    "\n",
    "# Average results\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RANDOM FOREST - AVERAGE RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"MSE: {rf_results_df['mse'].mean():.6f} ± {rf_results_df['mse'].std():.6f}\")\n",
    "print(f\"MAE: {rf_results_df['mae'].mean():.6f} ± {rf_results_df['mae'].std():.6f}\")\n",
    "print(f\"R²:  {rf_results_df['r2'].mean():.6f} ± {rf_results_df['r2'].std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc8e62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final Random Forest on all data...\n",
      "Random Forest model saved\n",
      "Random Forest model saved\n"
     ]
    }
   ],
   "source": [
    "# Train final Random Forest on all data\n",
    "print(\"\\nTraining final Random Forest on all data...\")\n",
    "\n",
    "scaler_rf = StandardScaler()\n",
    "X_scaled = scaler_rf.fit_transform(X)\n",
    "\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_final.fit(X_scaled, y)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_final, CONFIG['artifacts_dir'] / 'rf_model.joblib')\n",
    "joblib.dump(scaler_rf, CONFIG['artifacts_dir'] / 'rf_scaler.joblib')\n",
    "\n",
    "print(\"Random Forest model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cdef6",
   "metadata": {},
   "source": [
    "## Model 2: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3de6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 2: LIGHTGBM\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5\n",
      "  MSE: 0.000146\n",
      "  MAE: 0.009297\n",
      "  R²: 0.000190\n",
      "\n",
      "Fold 2/5\n",
      "  MSE: 0.000098\n",
      "  MAE: 0.007094\n",
      "  R²: -0.001380\n",
      "\n",
      "Fold 3/5\n",
      "  MSE: 0.000173\n",
      "  MAE: 0.009303\n",
      "  R²: 0.002569\n",
      "\n",
      "Fold 4/5\n",
      "  MSE: 0.000067\n",
      "  MAE: 0.005709\n",
      "  R²: 0.001291\n",
      "\n",
      "Fold 5/5\n",
      "  MSE: 0.000129\n",
      "  MAE: 0.008121\n",
      "  R²: -0.000352\n",
      "\n",
      "==================================================\n",
      "LIGHTGBM - AVERAGE RESULTS\n",
      "==================================================\n",
      "MSE: 0.000123 ± 0.000041\n",
      "MAE: 0.007905 ± 0.001535\n",
      "R²:  0.000464 ± 0.001521\n",
      "  MSE: 0.000129\n",
      "  MAE: 0.008121\n",
      "  R²: -0.000352\n",
      "\n",
      "==================================================\n",
      "LIGHTGBM - AVERAGE RESULTS\n",
      "==================================================\n",
      "MSE: 0.000123 ± 0.000041\n",
      "MAE: 0.007905 ± 0.001535\n",
      "R²:  0.000464 ± 0.001521\n"
     ]
    }
   ],
   "source": [
    "if LGBM_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL 2: LIGHTGBM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    lgbm_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "        print(f\"\\nFold {fold}/{CONFIG['n_splits']}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train LightGBM\n",
    "        lgbm_model = lgb.LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            num_leaves=31,\n",
    "            min_child_samples=20,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        )\n",
    "        lgbm_model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_val_fold, y_val_fold)],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = lgbm_model.predict(X_val_fold)\n",
    "        y_pred = np.clip(y_pred, CONFIG['prediction_bounds'][0], CONFIG['prediction_bounds'][1])\n",
    "        \n",
    "        # Evaluate\n",
    "        mse = mean_squared_error(y_val_fold, y_pred)\n",
    "        mae = mean_absolute_error(y_val_fold, y_pred)\n",
    "        r2 = r2_score(y_val_fold, y_pred)\n",
    "        \n",
    "        lgbm_results.append({\n",
    "            'fold': fold,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        })\n",
    "        \n",
    "        print(f\"  MSE: {mse:.6f}\")\n",
    "        print(f\"  MAE: {mae:.6f}\")\n",
    "        print(f\"  R²: {r2:.6f}\")\n",
    "    \n",
    "    # Average results\n",
    "    lgbm_results_df = pd.DataFrame(lgbm_results)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"LIGHTGBM - AVERAGE RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"MSE: {lgbm_results_df['mse'].mean():.6f} ± {lgbm_results_df['mse'].std():.6f}\")\n",
    "    print(f\"MAE: {lgbm_results_df['mae'].mean():.6f} ± {lgbm_results_df['mae'].std():.6f}\")\n",
    "    print(f\"R²:  {lgbm_results_df['r2'].mean():.6f} ± {lgbm_results_df['r2'].std():.6f}\")\n",
    "else:\n",
    "    print(\"Skipping LightGBM (not installed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d04c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final LightGBM on all data...\n",
      "LightGBM model saved\n",
      "LightGBM model saved\n"
     ]
    }
   ],
   "source": [
    "if LGBM_AVAILABLE:\n",
    "    # Train final LightGBM on all data\n",
    "    print(\"\\nTraining final LightGBM on all data...\")\n",
    "    \n",
    "    lgbm_final = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgbm_final.fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(lgbm_final, CONFIG['artifacts_dir'] / 'lgbm_model.joblib')\n",
    "    \n",
    "    print(\"LightGBM model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9961d",
   "metadata": {},
   "source": [
    "## Model 3: LSTM (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "280baffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 3: LSTM\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5\n",
      "  MSE: 0.000261\n",
      "  MAE: 0.011765\n",
      "  R²: -0.785772\n",
      "  Epochs trained: 13\n",
      "\n",
      "Fold 2/5\n",
      "  MSE: 0.000261\n",
      "  MAE: 0.011765\n",
      "  R²: -0.785772\n",
      "  Epochs trained: 13\n",
      "\n",
      "Fold 2/5\n",
      "  MSE: 0.000097\n",
      "  MAE: 0.007091\n",
      "  R²: 0.003345\n",
      "  Epochs trained: 37\n",
      "\n",
      "Fold 3/5\n",
      "  MSE: 0.000097\n",
      "  MAE: 0.007091\n",
      "  R²: 0.003345\n",
      "  Epochs trained: 37\n",
      "\n",
      "Fold 3/5\n",
      "  MSE: 0.000316\n",
      "  MAE: 0.013467\n",
      "  R²: -0.824913\n",
      "  Epochs trained: 25\n",
      "\n",
      "Fold 4/5\n",
      "  MSE: 0.000316\n",
      "  MAE: 0.013467\n",
      "  R²: -0.824913\n",
      "  Epochs trained: 25\n",
      "\n",
      "Fold 4/5\n",
      "  MSE: 0.000067\n",
      "  MAE: 0.005727\n",
      "  R²: 0.000429\n",
      "  Epochs trained: 15\n",
      "\n",
      "Fold 5/5\n",
      "  MSE: 0.000067\n",
      "  MAE: 0.005727\n",
      "  R²: 0.000429\n",
      "  Epochs trained: 15\n",
      "\n",
      "Fold 5/5\n",
      "  MSE: 0.000127\n",
      "  MAE: 0.008092\n",
      "  R²: 0.011495\n",
      "  Epochs trained: 14\n",
      "\n",
      "==================================================\n",
      "LSTM - AVERAGE RESULTS\n",
      "==================================================\n",
      "MSE: 0.000174 ± 0.000109\n",
      "MAE: 0.009228 ± 0.003260\n",
      "R²:  -0.319083 ± 0.444126\n",
      "  MSE: 0.000127\n",
      "  MAE: 0.008092\n",
      "  R²: 0.011495\n",
      "  Epochs trained: 14\n",
      "\n",
      "==================================================\n",
      "LSTM - AVERAGE RESULTS\n",
      "==================================================\n",
      "MSE: 0.000174 ± 0.000109\n",
      "MAE: 0.009228 ± 0.003260\n",
      "R²:  -0.319083 ± 0.444126\n"
     ]
    }
   ],
   "source": [
    "if LSTM_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL 3: LSTM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Prepare data for LSTM (need 3D input: samples, timesteps, features)\n",
    "    # We'll use a simple approach: each sample is a single timestep\n",
    "    \n",
    "    lstm_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "        print(f\"\\nFold {fold}/{CONFIG['n_splits']}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Reshape for LSTM (samples, timesteps, features)\n",
    "        X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "        X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "        \n",
    "        # Build LSTM model\n",
    "        model = Sequential([\n",
    "            LSTM(50, activation='relu', input_shape=(1, len(FEATURE_COLS)), return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(25, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train_lstm, y_train_fold,\n",
    "            validation_data=(X_val_lstm, y_val_fold),\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_val_lstm, verbose=0).flatten()\n",
    "        y_pred = np.clip(y_pred, CONFIG['prediction_bounds'][0], CONFIG['prediction_bounds'][1])\n",
    "        \n",
    "        # Evaluate\n",
    "        mse = mean_squared_error(y_val_fold, y_pred)\n",
    "        mae = mean_absolute_error(y_val_fold, y_pred)\n",
    "        r2 = r2_score(y_val_fold, y_pred)\n",
    "        \n",
    "        lstm_results.append({\n",
    "            'fold': fold,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        })\n",
    "        \n",
    "        print(f\"  MSE: {mse:.6f}\")\n",
    "        print(f\"  MAE: {mae:.6f}\")\n",
    "        print(f\"  R²: {r2:.6f}\")\n",
    "        print(f\"  Epochs trained: {len(history.history['loss'])}\")\n",
    "    \n",
    "    # Average results\n",
    "    lstm_results_df = pd.DataFrame(lstm_results)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"LSTM - AVERAGE RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"MSE: {lstm_results_df['mse'].mean():.6f} ± {lstm_results_df['mse'].std():.6f}\")\n",
    "    print(f\"MAE: {lstm_results_df['mae'].mean():.6f} ± {lstm_results_df['mae'].std():.6f}\")\n",
    "    print(f\"R²:  {lstm_results_df['r2'].mean():.6f} ± {lstm_results_df['r2'].std():.6f}\")\n",
    "else:\n",
    "    print(\"Skipping LSTM (TensorFlow not installed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf7bb494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final LSTM on all data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model saved\n"
     ]
    }
   ],
   "source": [
    "if LSTM_AVAILABLE:\n",
    "    # Train final LSTM on all data\n",
    "    print(\"\\nTraining final LSTM on all data...\")\n",
    "    \n",
    "    scaler_lstm = StandardScaler()\n",
    "    X_scaled = scaler_lstm.fit_transform(X)\n",
    "    X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "    \n",
    "    lstm_final = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(1, len(FEATURE_COLS)), return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(25, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    lstm_final.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "    \n",
    "    lstm_final.fit(\n",
    "        X_lstm, y,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    lstm_final.save(CONFIG['artifacts_dir'] / 'lstm_model.h5')\n",
    "    joblib.dump(scaler_lstm, CONFIG['artifacts_dir'] / 'lstm_scaler.joblib')\n",
    "    \n",
    "    print(\"LSTM model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755fe44",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9f765bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "======================================================================\n",
      "        Model                 MSE                 MAE                   R²\n",
      "Random Forest 0.000126 ± 0.000041 0.007996 ± 0.001515 -0.029979 ± 0.028240\n",
      "     LightGBM 0.000123 ± 0.000041 0.007905 ± 0.001535  0.000464 ± 0.001521\n",
      "         LSTM 0.000174 ± 0.000109 0.009228 ± 0.003260 -0.319083 ± 0.444126\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = []\n",
    "\n",
    "# Random Forest\n",
    "comparison.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'MSE': f\"{rf_results_df['mse'].mean():.6f} ± {rf_results_df['mse'].std():.6f}\",\n",
    "    'MAE': f\"{rf_results_df['mae'].mean():.6f} ± {rf_results_df['mae'].std():.6f}\",\n",
    "    'R²': f\"{rf_results_df['r2'].mean():.6f} ± {rf_results_df['r2'].std():.6f}\"\n",
    "})\n",
    "\n",
    "# LightGBM\n",
    "if LGBM_AVAILABLE:\n",
    "    comparison.append({\n",
    "        'Model': 'LightGBM',\n",
    "        'MSE': f\"{lgbm_results_df['mse'].mean():.6f} ± {lgbm_results_df['mse'].std():.6f}\",\n",
    "        'MAE': f\"{lgbm_results_df['mae'].mean():.6f} ± {lgbm_results_df['mae'].std():.6f}\",\n",
    "        'R²': f\"{lgbm_results_df['r2'].mean():.6f} ± {lgbm_results_df['r2'].std():.6f}\"\n",
    "    })\n",
    "\n",
    "# LSTM\n",
    "if LSTM_AVAILABLE:\n",
    "    comparison.append({\n",
    "        'Model': 'LSTM',\n",
    "        'MSE': f\"{lstm_results_df['mse'].mean():.6f} ± {lstm_results_df['mse'].std():.6f}\",\n",
    "        'MAE': f\"{lstm_results_df['mae'].mean():.6f} ± {lstm_results_df['mae'].std():.6f}\",\n",
    "        'R²': f\"{lstm_results_df['r2'].mean():.6f} ± {lstm_results_df['r2'].std():.6f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(CONFIG['results_dir'] / 'model_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44857b85",
   "metadata": {},
   "source": [
    "## Volatility Check\n",
    "\n",
    "Ensure predictions don't exceed 120% of benchmark volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "791d3395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VOLATILITY ANALYSIS\n",
      "======================================================================\n",
      "Target (benchmark) volatility: 0.010541\n",
      "Prediction volatility: 0.001284\n",
      "Volatility ratio: 12.18%\n",
      "Max allowed ratio: 120%\n",
      "Volatility constraint satisfied\n"
     ]
    }
   ],
   "source": [
    "# Calculate volatility of predictions vs target\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VOLATILITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get predictions from best model (Random Forest for now)\n",
    "X_scaled_all = scaler_rf.transform(X)\n",
    "predictions = rf_final.predict(X_scaled_all)\n",
    "predictions = np.clip(predictions, CONFIG['prediction_bounds'][0], CONFIG['prediction_bounds'][1])\n",
    "\n",
    "# Calculate volatilities\n",
    "target_vol = y.std()\n",
    "pred_vol = predictions.std()\n",
    "vol_ratio = pred_vol / target_vol\n",
    "\n",
    "print(f\"Target (benchmark) volatility: {target_vol:.6f}\")\n",
    "print(f\"Prediction volatility: {pred_vol:.6f}\")\n",
    "print(f\"Volatility ratio: {vol_ratio:.2%}\")\n",
    "print(f\"Max allowed ratio: {CONFIG['max_volatility_ratio']:.0%}\")\n",
    "\n",
    "if vol_ratio <= CONFIG['max_volatility_ratio']:\n",
    "    print(f\"Volatility constraint satisfied\")\n",
    "else:\n",
    "    print(f\"Warning: Volatility exceeds {CONFIG['max_volatility_ratio']:.0%} threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c71b97",
   "metadata": {},
   "source": [
    "## Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "517679a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TOP 10 MOST IMPORTANT FEATURES (Random Forest)\n",
      "======================================================================\n",
      "feature  importance\n",
      "     M4    0.127265\n",
      "     P8    0.077283\n",
      "    E17    0.075593\n",
      "    V13    0.073020\n",
      "     V7    0.069702\n",
      "     P6    0.060576\n",
      "     I2    0.056485\n",
      "    M11    0.051198\n",
      "     P5    0.050878\n",
      "    P11    0.050763\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': FEATURE_COLS,\n",
    "    'importance': rf_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 10 MOST IMPORTANT FEATURES (Random Forest)\")\n",
    "print(\"=\"*70)\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'][:10], feature_importance['importance'][:10])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importance (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['results_dir'] / 'feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission file for Kaggle Competition\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING SUBMISSION FILE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Force Kaggle path detection\n",
    "IS_KAGGLE = Path('/kaggle/input').exists()\n",
    "print(f\"Environment: {'KAGGLE' if IS_KAGGLE else 'LOCAL'}\")\n",
    "\n",
    "# Always use /kaggle/working on Kaggle, results dir locally  \n",
    "if IS_KAGGLE:\n",
    "    submission_path = Path('/kaggle/working/submission.csv')\n",
    "else:\n",
    "    submission_path = CONFIG['results_dir'] / 'submission.csv'\n",
    "\n",
    "print(f\"Submission will be saved to: {submission_path}\")\n",
    "\n",
    "# Load test data and generate predictions\n",
    "test_path = CONFIG['test_data_path']\n",
    "print(f\"Looking for test data at: {test_path}\")\n",
    "\n",
    "if not Path(test_path).exists():\n",
    "    print(f\"ERROR: Test file not found!\")\n",
    "    raise FileNotFoundError(f\"Cannot create submission without test data at {test_path}\")\n",
    "\n",
    "test_df = pd.read_csv(test_path)\n",
    "print(f\"✓ Loaded test data: {test_df.shape}\")\n",
    "\n",
    "# Verify all required features are present\n",
    "missing = [c for c in FEATURE_COLS if c not in test_df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Test data missing required features: {missing}\")\n",
    "\n",
    "# Prepare test features\n",
    "X_test = test_df[FEATURE_COLS].copy().ffill().bfill()\n",
    "X_test_scaled = scaler_rf.transform(X_test)\n",
    "\n",
    "# Generate predictions using Random Forest\n",
    "test_pred = rf_final.predict(X_test_scaled)\n",
    "test_pred = np.clip(test_pred, CONFIG['prediction_bounds'][0], CONFIG['prediction_bounds'][1])\n",
    "print(f\"✓ Generated {len(test_pred)} predictions\")\n",
    "\n",
    "# Create submission DataFrame - check for sample_submission to get correct format\n",
    "sample_sub_path = Path('/kaggle/input/hull-tactical-market-prediction/sample_submission.csv')\n",
    "if sample_sub_path.exists():\n",
    "    print(f\"✓ Found sample_submission.csv\")\n",
    "    sample_sub = pd.read_csv(sample_sub_path)\n",
    "    id_col = sample_sub.columns[0]\n",
    "    print(f\"  Using ID column: '{id_col}'\")\n",
    "    submission_df = pd.DataFrame({\n",
    "        id_col: test_df[id_col] if id_col in test_df.columns else range(len(test_df)),\n",
    "        'prediction': test_pred\n",
    "    })\n",
    "elif 'id' in test_df.columns:\n",
    "    print(f\"  Using 'id' column from test data\")\n",
    "    submission_df = pd.DataFrame({'id': test_df['id'], 'prediction': test_pred})\n",
    "else:\n",
    "    print(f\"  Using 'row' as ID column\")\n",
    "    submission_df = pd.DataFrame({'row': np.arange(len(test_df)), 'prediction': test_pred})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"✓ Submission saved: {submission_path}\")\n",
    "print(f\"  Shape: {submission_df.shape}\")\n",
    "print(f\"  Prediction range: [{test_pred.min():.6f}, {test_pred.max():.6f}]\")\n",
    "\n",
    "# Verify file was written\n",
    "if submission_path.exists():\n",
    "    size = submission_path.stat().st_size\n",
    "    print(f\"✓ File verified: {size:,} bytes\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Failed to write submission file to {submission_path}\")\n",
    "\n",
    "# Verify all output files exist\n",
    "print(\"\\nVerifying output files:\")\n",
    "expected = [\n",
    "    submission_path,\n",
    "    CONFIG['artifacts_dir'] / 'rf_model.joblib',\n",
    "    CONFIG['artifacts_dir'] / 'rf_scaler.joblib',\n",
    "    CONFIG['results_dir'] / 'feature_importance.png',\n",
    "    CONFIG['results_dir'] / 'model_comparison.csv',\n",
    "]\n",
    "\n",
    "for p in expected:\n",
    "    exists = Path(p).exists()\n",
    "    size = Path(p).stat().st_size if exists else 0\n",
    "    status = '✓' if exists else '✗'\n",
    "    print(f\"  {p.name}: {status} ({size:,} bytes)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cd9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final confirmation and Kaggle output declaration\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOTEBOOK EXECUTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# CRITICAL: Ensure submission file is in the correct location for Kaggle\n",
    "# Check BOTH possible locations since path logic might be wrong\n",
    "kaggle_submission = Path('/kaggle/working/submission.csv')\n",
    "local_submission = CONFIG['results_dir'] / 'submission.csv'\n",
    "\n",
    "# Find where the file actually is\n",
    "if kaggle_submission.exists():\n",
    "    submission_file = kaggle_submission\n",
    "    print(f\"✓ Submission file found at: {submission_file}\")\n",
    "elif local_submission.exists():\n",
    "    submission_file = local_submission\n",
    "    print(f\"WARNING: Submission file at wrong location: {submission_file}\")\n",
    "    # Copy to correct Kaggle location if we're on Kaggle\n",
    "    if Path('/kaggle/working').exists():\n",
    "        import shutil\n",
    "        shutil.copy(submission_file, kaggle_submission)\n",
    "        submission_file = kaggle_submission\n",
    "        print(f\"✓ Copied to correct location: {submission_file}\")\n",
    "else:\n",
    "    print(f\"✗ ERROR: Submission file not found at either location:\")\n",
    "    print(f\"  - {kaggle_submission}\")\n",
    "    print(f\"  - {local_submission}\")\n",
    "    raise FileNotFoundError(f\"Submission file not created!\")\n",
    "\n",
    "print(f\"Size: {submission_file.stat().st_size:,} bytes\")\n",
    "\n",
    "# Read and validate submission\n",
    "sub_df = pd.read_csv(submission_file)\n",
    "print(f\"Shape: {sub_df.shape}\")\n",
    "print(f\"Columns: {list(sub_df.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(sub_df.head())\n",
    "\n",
    "# Validate submission format\n",
    "if sub_df.shape[0] == 0:\n",
    "    raise ValueError(\"Submission file is empty!\")\n",
    "if sub_df.isnull().any().any():\n",
    "    raise ValueError(\"Submission contains null values!\")\n",
    "\n",
    "print(f\"\\n✓ Submission file validated successfully\")\n",
    "print(f\"✓ Ready for Kaggle competition submission\")\n",
    "print(f\"\\n** SUBMISSION FILE LOCATION: {submission_file.absolute()} **\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
